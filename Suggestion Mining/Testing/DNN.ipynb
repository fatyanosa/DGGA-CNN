{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JQglc7UkQ5pa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import backend as K\n",
    "\n",
    "class utility:\n",
    "\n",
    "    def read_CSV(self, filename):\n",
    "        df = pd.read_csv(filename)\n",
    "        return df\n",
    "\n",
    "    def get_text_label(self, df):\n",
    "        texts = []  # list of text samples\n",
    "        labels = []  # list of label ids\n",
    "        for index, row in df.iterrows():\n",
    "            if isinstance(row['sentence'], float):\n",
    "                texts.append(str(row['sentence']))\n",
    "            else:\n",
    "                texts.append(row['sentence'])\n",
    "\n",
    "            labels.append(row['label'])\n",
    "\n",
    "        return texts, labels\n",
    "\n",
    "    def tokenize_texts(self, texts):\n",
    "        tokenizer = Tokenizer(num_words=10000)\n",
    "        tokenizer.fit_on_texts(texts)\n",
    "\n",
    "        return tokenizer\n",
    "\n",
    "    def padding_texts(self, texts, maxlen):\n",
    "\n",
    "        texts = pad_sequences(texts, padding='post', maxlen=maxlen)\n",
    "\n",
    "        return texts\n",
    "\n",
    "    def get_metric(self, y_true, y_pred):\n",
    "        accuracyScore = accuracy_score(y_true, y_pred)\n",
    "\n",
    "        # binary: Only report results for the class specified by pos_label. This is applicable only if targets (y_{true,pred}) are binary.\n",
    "        precisionScoreBinary = precision_score(y_true, y_pred, average='binary')\n",
    "        recallScoreBinary = recall_score(y_true, y_pred, average='binary')\n",
    "        f1ScoreBinary = f1_score(y_true, y_pred, average='binary')\n",
    "\n",
    "        return accuracyScore, precisionScoreBinary, recallScoreBinary, f1ScoreBinary\n",
    "\n",
    "    def print_metric(self, accuracyScore, precisionScoreBinary, recallScoreBinary, f1ScoreBinary):\n",
    "        print(\"Accuracy: {}\".format(str(accuracyScore)))\n",
    "        print(\"Precision: {}\".format(str(precisionScoreBinary)))\n",
    "        print(\"Recall: {}\".format(str(recallScoreBinary)))\n",
    "        print(\"F1-Score: {}\".format(str(f1ScoreBinary)))\n",
    "        print(\"{},{},{},{}\".format(str(accuracyScore), str(precisionScoreBinary), str(recallScoreBinary), str(f1ScoreBinary)))\n",
    "        \n",
    "\n",
    "    def get_testing_metric(self, y_test, y_pred):\n",
    "        # metric for Testing Data\n",
    "        # print(\"Testing Data\")\n",
    "        accuracyScore, precisionScoreBinary, recallScoreBinary, f1ScoreBinary = self.get_metric(y_test, y_pred)\n",
    "        # print()\n",
    "\n",
    "        return accuracyScore, precisionScoreBinary, recallScoreBinary, f1ScoreBinary\n",
    "\n",
    "    def write_df_csv(self, df, out_path):\n",
    "        df.to_csv(out_path, index=False)\n",
    "\n",
    "    def create_embedding_matrix(self, filepath, word_index, embedding_dim):\n",
    "        vocab_size = len(word_index) + 1  # Adding again 1 because of reserved 0 index\n",
    "        embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "        with open(filepath, encoding=\"utf8\") as f:\n",
    "            for line in f:\n",
    "                word, *vector = line.split()\n",
    "                if word in word_index:\n",
    "                    idx = word_index[word]\n",
    "                    embedding_matrix[idx] = np.array(\n",
    "                        vector, dtype=np.float32)[:embedding_dim]\n",
    "\n",
    "        return embedding_matrix\n",
    "\n",
    "    def get_max_length_of_sentences(self, texts):\n",
    "        maxlength = 0\n",
    "        for text in texts:\n",
    "            if (len(text.split()) > maxlength):\n",
    "                maxlength = len(text.split())\n",
    "\n",
    "        return maxlength\n",
    "\n",
    "    def get_training_trial_data(self, textsTraining, labelsTraining, textsTrial, labelsTrial, glovePath):\n",
    "        textsTraining, textsTesting = np.asarray(textsTraining), np.asarray(textsTrial)\n",
    "        y_train, y_val = np.asarray(labelsTraining), np.asarray(labelsTrial)\n",
    "\n",
    "        # Tokenize words\n",
    "        tokenizer = self.tokenize_texts(textsTraining)\n",
    "        X_train = tokenizer.texts_to_sequences(textsTraining)\n",
    "        X_val = tokenizer.texts_to_sequences(textsTesting)\n",
    "\n",
    "        # Adding 1 because of reserved 0 index\n",
    "        vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "        # get maxlen\n",
    "        maxlen = self.get_max_length_of_sentences(textsTraining)\n",
    "\n",
    "        # Pad sequences with zeros\n",
    "        X_train = self.padding_texts(X_train, maxlen)\n",
    "        X_val = self.padding_texts(X_val, maxlen)\n",
    "\n",
    "        embedding_matrix = []\n",
    "        embedding_matrix.append(self.create_embedding_matrix(glovePath[0], tokenizer.word_index, 50))\n",
    "        embedding_matrix.append(self.create_embedding_matrix(glovePath[1], tokenizer.word_index, 100))\n",
    "        embedding_matrix.append(self.create_embedding_matrix(glovePath[2], tokenizer.word_index, 200))\n",
    "        embedding_matrix.append(self.create_embedding_matrix(glovePath[3], tokenizer.word_index, 300))\n",
    "\n",
    "        return X_train, X_val, y_train, y_val, vocab_size, maxlen, embedding_matrix\n",
    "\n",
    "    def Average(self, list):\n",
    "        return sum(list) / len(list)\n",
    "    \n",
    "    def recall_m(self, y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision_m(self, y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    def f1_m(self, y_true, y_pred):\n",
    "        precision = self.precision_m(y_true, y_pred)\n",
    "        recall = self.recall_m(y_true, y_pred)\n",
    "        return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "id": "8bgSw_Pachda",
    "outputId": "6714e41e-3ab8-4d74-9008-8079aea37af3"
   },
   "outputs": [],
   "source": [
    "dataTraining = 'TrainingTrialData.csv'\n",
    "dataTesting = 'EvaluationData.csv'\n",
    "\n",
    "root_path = '/lab/dbms/fatyanosa'\n",
    "datasetPath = '{}/Dataset/Suggestion Mining/'.format(root_path)\n",
    "resultsPath = '{}/Server1/Suggestion Mining/Results/'.format(root_path)\n",
    "archPath = '{}/Server1/Suggestion Mining/Architecture/'.format(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "util = utility()\n",
    "n_run = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "gMKFfK-Ocayx",
    "outputId": "efcdda73-086f-4c91-dad9-a6650e5393f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "9900 train sequences\n",
      "1657 test sequences\n",
      "x_train shape: (9900, 183)\n",
      "x_test shape: (1657, 183)\n",
      "Build model...\n",
      "Train...\n",
      "Train on 9900 samples, validate on 1657 samples\n",
      "Epoch 1/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2707 - f1_m: 0.4313\n",
      "Epoch 00001: val_f1_m improved from -inf to 0.30977, saving model to /lab/dbms/fatyanosa/Server1/Suggestion Mining/Architecture/LSTM.h5\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2708 - f1_m: 0.4320 - val_loss: 0.2642 - val_f1_m: 0.3098\n",
      "Epoch 2/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2706 - f1_m: 0.4369\n",
      "Epoch 00002: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2706 - f1_m: 0.4368 - val_loss: 0.2647 - val_f1_m: 0.3098\n",
      "Epoch 3/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4310\n",
      "Epoch 00003: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 54s 5ms/sample - loss: 0.2704 - f1_m: 0.4306 - val_loss: 0.2646 - val_f1_m: 0.3098\n",
      "Epoch 4/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4369\n",
      "Epoch 00004: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 54s 5ms/sample - loss: 0.2705 - f1_m: 0.4367 - val_loss: 0.2647 - val_f1_m: 0.3098\n",
      "Epoch 5/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4368\n",
      "Epoch 00005: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2705 - f1_m: 0.4367 - val_loss: 0.2642 - val_f1_m: 0.3098\n",
      "Epoch 6/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4358\n",
      "Epoch 00006: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4363 - val_loss: 0.2648 - val_f1_m: 0.3098\n",
      "Epoch 7/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4370\n",
      "Epoch 00007: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4375 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 8/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4367\n",
      "Epoch 00008: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 54s 5ms/sample - loss: 0.2704 - f1_m: 0.4375 - val_loss: 0.2646 - val_f1_m: 0.3098\n",
      "Epoch 9/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4353\n",
      "Epoch 00009: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2704 - f1_m: 0.4348 - val_loss: 0.2641 - val_f1_m: 0.3098\n",
      "Epoch 10/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4364\n",
      "Epoch 00010: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2704 - f1_m: 0.4363 - val_loss: 0.2641 - val_f1_m: 0.3098\n",
      "Epoch 11/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4360\n",
      "Epoch 00011: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2704 - f1_m: 0.4355 - val_loss: 0.2651 - val_f1_m: 0.3098\n",
      "Epoch 00011: early stopping\n",
      "620.9188227653503\n",
      "0.41586998087954113\n",
      "Build model...\n",
      "Train...\n",
      "Train on 9900 samples, validate on 1657 samples\n",
      "Epoch 1/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2709 - f1_m: 0.4338\n",
      "Epoch 00001: val_f1_m improved from -inf to 0.30977, saving model to /lab/dbms/fatyanosa/Server1/Suggestion Mining/Architecture/LSTM.h5\n",
      "9900/9900 [==============================] - 60s 6ms/sample - loss: 0.2710 - f1_m: 0.4340 - val_loss: 0.2644 - val_f1_m: 0.3098\n",
      "Epoch 2/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4371\n",
      "Epoch 00002: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2705 - f1_m: 0.4373 - val_loss: 0.2651 - val_f1_m: 0.3098\n",
      "Epoch 3/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4357\n",
      "Epoch 00003: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2705 - f1_m: 0.4362 - val_loss: 0.2642 - val_f1_m: 0.3098\n",
      "Epoch 4/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2706 - f1_m: 0.4366\n",
      "Epoch 00004: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2705 - f1_m: 0.4361 - val_loss: 0.2644 - val_f1_m: 0.3098\n",
      "Epoch 5/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4358\n",
      "Epoch 00005: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2705 - f1_m: 0.4365 - val_loss: 0.2646 - val_f1_m: 0.3098\n",
      "Epoch 6/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4372\n",
      "Epoch 00006: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2705 - f1_m: 0.4367 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 7/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4364\n",
      "Epoch 00007: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2704 - f1_m: 0.4366 - val_loss: 0.2651 - val_f1_m: 0.3098\n",
      "Epoch 8/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4363\n",
      "Epoch 00008: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2704 - f1_m: 0.4358 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 9/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4371\n",
      "Epoch 00009: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2704 - f1_m: 0.4362 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 10/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4358\n",
      "Epoch 00010: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 60s 6ms/sample - loss: 0.2704 - f1_m: 0.4363 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 11/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4370\n",
      "Epoch 00011: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2704 - f1_m: 0.4361 - val_loss: 0.2647 - val_f1_m: 0.3098\n",
      "Epoch 00011: early stopping\n",
      "647.0819146633148\n",
      "0.41586998087954113\n",
      "Build model...\n",
      "Train...\n",
      "Train on 9900 samples, validate on 1657 samples\n",
      "Epoch 1/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2709 - f1_m: 0.4312\n",
      "Epoch 00001: val_f1_m improved from -inf to 0.30977, saving model to /lab/dbms/fatyanosa/Server1/Suggestion Mining/Architecture/LSTM.h5\n",
      "9900/9900 [==============================] - 61s 6ms/sample - loss: 0.2709 - f1_m: 0.4308 - val_loss: 0.2656 - val_f1_m: 0.3098\n",
      "Epoch 2/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4370\n",
      "Epoch 00002: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2705 - f1_m: 0.4372 - val_loss: 0.2647 - val_f1_m: 0.3098\n",
      "Epoch 3/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2706 - f1_m: 0.4371\n",
      "Epoch 00003: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2706 - f1_m: 0.4366 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 4/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4354\n",
      "Epoch 00004: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2705 - f1_m: 0.4356 - val_loss: 0.2652 - val_f1_m: 0.3098\n",
      "Epoch 5/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2703 - f1_m: 0.4337\n",
      "Epoch 00005: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2703 - f1_m: 0.4336 - val_loss: 0.2650 - val_f1_m: 0.3098\n",
      "Epoch 6/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2703 - f1_m: 0.4368\n",
      "Epoch 00006: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2703 - f1_m: 0.4370 - val_loss: 0.2641 - val_f1_m: 0.3098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4370\n",
      "Epoch 00007: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2704 - f1_m: 0.4369 - val_loss: 0.2644 - val_f1_m: 0.3098\n",
      "Epoch 8/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2703 - f1_m: 0.4357\n",
      "Epoch 00008: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 60s 6ms/sample - loss: 0.2704 - f1_m: 0.4367 - val_loss: 0.2657 - val_f1_m: 0.3098\n",
      "Epoch 9/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4362\n",
      "Epoch 00009: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2704 - f1_m: 0.4357 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 10/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4363\n",
      "Epoch 00010: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2704 - f1_m: 0.4358 - val_loss: 0.2646 - val_f1_m: 0.3098\n",
      "Epoch 11/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4364\n",
      "Epoch 00011: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2704 - f1_m: 0.4366 - val_loss: 0.2648 - val_f1_m: 0.3098\n",
      "Epoch 00011: early stopping\n",
      "649.3281900882721\n",
      "0.41586998087954113\n",
      "Build model...\n",
      "Train...\n",
      "Train on 9900 samples, validate on 1657 samples\n",
      "Epoch 1/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2706 - f1_m: 0.4350\n",
      "Epoch 00001: val_f1_m improved from -inf to 0.30977, saving model to /lab/dbms/fatyanosa/Server1/Suggestion Mining/Architecture/LSTM.h5\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2706 - f1_m: 0.4349 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 2/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2706 - f1_m: 0.4197\n",
      "Epoch 00002: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2706 - f1_m: 0.4192 - val_loss: 0.2647 - val_f1_m: 0.3098\n",
      "Epoch 3/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4362\n",
      "Epoch 00003: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2705 - f1_m: 0.4364 - val_loss: 0.2642 - val_f1_m: 0.3098\n",
      "Epoch 4/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4355\n",
      "Epoch 00004: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2705 - f1_m: 0.4365 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 5/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4373\n",
      "Epoch 00005: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2704 - f1_m: 0.4372 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 6/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4360\n",
      "Epoch 00006: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2705 - f1_m: 0.4364 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 7/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4357\n",
      "Epoch 00007: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4353 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 8/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4376\n",
      "Epoch 00008: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2704 - f1_m: 0.4371 - val_loss: 0.2642 - val_f1_m: 0.3098\n",
      "Epoch 9/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4372\n",
      "Epoch 00009: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2705 - f1_m: 0.4367 - val_loss: 0.2644 - val_f1_m: 0.3098\n",
      "Epoch 10/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4370\n",
      "Epoch 00010: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4375 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 11/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2703 - f1_m: 0.4361\n",
      "Epoch 00011: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2704 - f1_m: 0.4369 - val_loss: 0.2642 - val_f1_m: 0.3098\n",
      "Epoch 00011: early stopping\n",
      "632.5015625953674\n",
      "0.41586998087954113\n",
      "Build model...\n",
      "Train...\n",
      "Train on 9900 samples, validate on 1657 samples\n",
      "Epoch 1/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2708 - f1_m: 0.4195\n",
      "Epoch 00001: val_f1_m improved from -inf to 0.30977, saving model to /lab/dbms/fatyanosa/Server1/Suggestion Mining/Architecture/LSTM.h5\n",
      "9900/9900 [==============================] - 61s 6ms/sample - loss: 0.2709 - f1_m: 0.4201 - val_loss: 0.2644 - val_f1_m: 0.3098\n",
      "Epoch 2/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2707 - f1_m: 0.4366\n",
      "Epoch 00002: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2707 - f1_m: 0.4365 - val_loss: 0.2646 - val_f1_m: 0.3098\n",
      "Epoch 3/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4373\n",
      "Epoch 00003: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2704 - f1_m: 0.4363 - val_loss: 0.2641 - val_f1_m: 0.3098\n",
      "Epoch 4/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4372\n",
      "Epoch 00004: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2705 - f1_m: 0.4374 - val_loss: 0.2646 - val_f1_m: 0.3098\n",
      "Epoch 5/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4356\n",
      "Epoch 00005: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4358 - val_loss: 0.2648 - val_f1_m: 0.3098\n",
      "Epoch 6/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4371\n",
      "Epoch 00006: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2705 - f1_m: 0.4366 - val_loss: 0.2647 - val_f1_m: 0.3098\n",
      "Epoch 7/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4363\n",
      "Epoch 00007: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2704 - f1_m: 0.4365 - val_loss: 0.2651 - val_f1_m: 0.3098\n",
      "Epoch 8/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4371\n",
      "Epoch 00008: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2704 - f1_m: 0.4362 - val_loss: 0.2648 - val_f1_m: 0.3098\n",
      "Epoch 9/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4367\n",
      "Epoch 00009: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2704 - f1_m: 0.4369 - val_loss: 0.2650 - val_f1_m: 0.3098\n",
      "Epoch 10/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4367\n",
      "Epoch 00010: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2705 - f1_m: 0.4369 - val_loss: 0.2648 - val_f1_m: 0.3098\n",
      "Epoch 11/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4371\n",
      "Epoch 00011: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2704 - f1_m: 0.4370 - val_loss: 0.2649 - val_f1_m: 0.3098\n",
      "Epoch 00011: early stopping\n",
      "637.7615909576416\n",
      "0.41586998087954113\n",
      "Build model...\n",
      "Train...\n",
      "Train on 9900 samples, validate on 1657 samples\n",
      "Epoch 1/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2707 - f1_m: 0.4162\n",
      "Epoch 00001: val_f1_m improved from -inf to 0.30977, saving model to /lab/dbms/fatyanosa/Server1/Suggestion Mining/Architecture/LSTM.h5\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2706 - f1_m: 0.4157 - val_loss: 0.2641 - val_f1_m: 0.3098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4364\n",
      "Epoch 00002: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4363 - val_loss: 0.2654 - val_f1_m: 0.3098\n",
      "Epoch 3/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2706 - f1_m: 0.4373\n",
      "Epoch 00003: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4368 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 4/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4372\n",
      "Epoch 00004: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4379 - val_loss: 0.2650 - val_f1_m: 0.3098\n",
      "Epoch 5/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4359\n",
      "Epoch 00005: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2704 - f1_m: 0.4364 - val_loss: 0.2641 - val_f1_m: 0.3098\n",
      "Epoch 6/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4359\n",
      "Epoch 00006: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2704 - f1_m: 0.4361 - val_loss: 0.2642 - val_f1_m: 0.3098\n",
      "Epoch 7/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4363\n",
      "Epoch 00007: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4368 - val_loss: 0.2642 - val_f1_m: 0.3098\n",
      "Epoch 8/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4366\n",
      "Epoch 00008: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2704 - f1_m: 0.4364 - val_loss: 0.2646 - val_f1_m: 0.3098\n",
      "Epoch 9/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4362\n",
      "Epoch 00009: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4357 - val_loss: 0.2655 - val_f1_m: 0.3098\n",
      "Epoch 10/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4373\n",
      "Epoch 00010: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 54s 5ms/sample - loss: 0.2704 - f1_m: 0.4368 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 11/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4367\n",
      "Epoch 00011: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4362 - val_loss: 0.2646 - val_f1_m: 0.3098\n",
      "Epoch 00011: early stopping\n",
      "623.9814763069153\n",
      "0.41586998087954113\n",
      "Build model...\n",
      "Train...\n",
      "Train on 9900 samples, validate on 1657 samples\n",
      "Epoch 1/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2706 - f1_m: 0.4283\n",
      "Epoch 00001: val_f1_m improved from -inf to 0.30977, saving model to /lab/dbms/fatyanosa/Server1/Suggestion Mining/Architecture/LSTM.h5\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2706 - f1_m: 0.4285 - val_loss: 0.2661 - val_f1_m: 0.3098\n",
      "Epoch 2/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4361\n",
      "Epoch 00002: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2706 - f1_m: 0.4369 - val_loss: 0.2648 - val_f1_m: 0.3098\n",
      "Epoch 3/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2706 - f1_m: 0.4366\n",
      "Epoch 00003: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2705 - f1_m: 0.4357 - val_loss: 0.2646 - val_f1_m: 0.3098\n",
      "Epoch 4/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4366\n",
      "Epoch 00004: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2705 - f1_m: 0.4368 - val_loss: 0.2644 - val_f1_m: 0.3098\n",
      "Epoch 5/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4357\n",
      "Epoch 00005: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2705 - f1_m: 0.4365 - val_loss: 0.2644 - val_f1_m: 0.3098\n",
      "Epoch 6/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4367\n",
      "Epoch 00006: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2704 - f1_m: 0.4358 - val_loss: 0.2649 - val_f1_m: 0.3098\n",
      "Epoch 7/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4370\n",
      "Epoch 00007: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4369 - val_loss: 0.2644 - val_f1_m: 0.3098\n",
      "Epoch 8/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2702 - f1_m: 0.4364\n",
      "Epoch 00008: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2703 - f1_m: 0.4368 - val_loss: 0.2642 - val_f1_m: 0.3098\n",
      "Epoch 9/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4362\n",
      "Epoch 00009: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2704 - f1_m: 0.4361 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 10/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2703 - f1_m: 0.4365\n",
      "Epoch 00010: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4370 - val_loss: 0.2653 - val_f1_m: 0.3098\n",
      "Epoch 11/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4366\n",
      "Epoch 00011: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2704 - f1_m: 0.4365 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 00011: early stopping\n",
      "633.9765620231628\n",
      "0.41586998087954113\n",
      "Build model...\n",
      "Train...\n",
      "Train on 9900 samples, validate on 1657 samples\n",
      "Epoch 1/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2707 - f1_m: 0.4361\n",
      "Epoch 00001: val_f1_m improved from -inf to 0.30977, saving model to /lab/dbms/fatyanosa/Server1/Suggestion Mining/Architecture/LSTM.h5\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2707 - f1_m: 0.4368 - val_loss: 0.2641 - val_f1_m: 0.3098\n",
      "Epoch 2/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4294\n",
      "Epoch 00002: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4299 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 3/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4367\n",
      "Epoch 00003: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2705 - f1_m: 0.4369 - val_loss: 0.2644 - val_f1_m: 0.3098\n",
      "Epoch 4/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4373\n",
      "Epoch 00004: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4368 - val_loss: 0.2648 - val_f1_m: 0.3098\n",
      "Epoch 5/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4372\n",
      "Epoch 00005: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4374 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 6/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4364\n",
      "Epoch 00006: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4363 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 7/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4364\n",
      "Epoch 00007: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4366 - val_loss: 0.2644 - val_f1_m: 0.3098\n",
      "Epoch 8/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4363\n",
      "Epoch 00008: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2704 - f1_m: 0.4368 - val_loss: 0.2645 - val_f1_m: 0.3098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2703 - f1_m: 0.4362\n",
      "Epoch 00009: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2703 - f1_m: 0.4364 - val_loss: 0.2641 - val_f1_m: 0.3098\n",
      "Epoch 10/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4362\n",
      "Epoch 00010: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4367 - val_loss: 0.2648 - val_f1_m: 0.3098\n",
      "Epoch 11/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4371\n",
      "Epoch 00011: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2704 - f1_m: 0.4369 - val_loss: 0.2647 - val_f1_m: 0.3098\n",
      "Epoch 00011: early stopping\n",
      "622.2800266742706\n",
      "0.41586998087954113\n",
      "Build model...\n",
      "Train...\n",
      "Train on 9900 samples, validate on 1657 samples\n",
      "Epoch 1/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2708 - f1_m: 0.4220\n",
      "Epoch 00001: val_f1_m improved from -inf to 0.30977, saving model to /lab/dbms/fatyanosa/Server1/Suggestion Mining/Architecture/LSTM.h5\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2708 - f1_m: 0.4228 - val_loss: 0.2641 - val_f1_m: 0.3098\n",
      "Epoch 2/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2706 - f1_m: 0.4370\n",
      "Epoch 00002: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2706 - f1_m: 0.4365 - val_loss: 0.2649 - val_f1_m: 0.3098\n",
      "Epoch 3/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4329\n",
      "Epoch 00003: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2705 - f1_m: 0.4327 - val_loss: 0.2646 - val_f1_m: 0.3098\n",
      "Epoch 4/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4359\n",
      "Epoch 00004: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4363 - val_loss: 0.2644 - val_f1_m: 0.3098\n",
      "Epoch 5/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4366\n",
      "Epoch 00005: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4371 - val_loss: 0.2653 - val_f1_m: 0.3098\n",
      "Epoch 6/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4370\n",
      "Epoch 00006: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4374 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 7/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4360\n",
      "Epoch 00007: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2705 - f1_m: 0.4362 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 8/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4362\n",
      "Epoch 00008: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4360 - val_loss: 0.2649 - val_f1_m: 0.3098\n",
      "Epoch 9/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4368\n",
      "Epoch 00009: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2704 - f1_m: 0.4359 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 10/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4367\n",
      "Epoch 00010: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4370 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 11/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4369\n",
      "Epoch 00011: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2704 - f1_m: 0.4371 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 00011: early stopping\n",
      "626.551246881485\n",
      "0.41586998087954113\n",
      "Build model...\n",
      "Train...\n",
      "Train on 9900 samples, validate on 1657 samples\n",
      "Epoch 1/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2708 - f1_m: 0.4342\n",
      "Epoch 00001: val_f1_m improved from -inf to 0.30977, saving model to /lab/dbms/fatyanosa/Server1/Suggestion Mining/Architecture/LSTM.h5\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2707 - f1_m: 0.4338 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 2/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4370\n",
      "Epoch 00002: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2705 - f1_m: 0.4374 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 3/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4364\n",
      "Epoch 00003: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2705 - f1_m: 0.4369 - val_loss: 0.2646 - val_f1_m: 0.3098\n",
      "Epoch 4/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4365\n",
      "Epoch 00004: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2705 - f1_m: 0.4361 - val_loss: 0.2662 - val_f1_m: 0.3098\n",
      "Epoch 5/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4373\n",
      "Epoch 00005: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4372 - val_loss: 0.2644 - val_f1_m: 0.3098\n",
      "Epoch 6/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4374\n",
      "Epoch 00006: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4369 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 7/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4350\n",
      "Epoch 00007: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4349 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 8/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4379\n",
      "Epoch 00008: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2704 - f1_m: 0.4365 - val_loss: 0.2646 - val_f1_m: 0.3098\n",
      "Epoch 9/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4360\n",
      "Epoch 00009: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4369 - val_loss: 0.2644 - val_f1_m: 0.3098\n",
      "Epoch 10/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4358\n",
      "Epoch 00010: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2704 - f1_m: 0.4363 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 11/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4369\n",
      "Epoch 00011: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2704 - f1_m: 0.4374 - val_loss: 0.2648 - val_f1_m: 0.3098\n",
      "Epoch 00011: early stopping\n",
      "625.8986051082611\n",
      "0.41586998087954113\n",
      "Build model...\n",
      "Train...\n",
      "Train on 9900 samples, validate on 1657 samples\n",
      "Epoch 1/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2709 - f1_m: 0.4336\n",
      "Epoch 00001: val_f1_m improved from -inf to 0.30977, saving model to /lab/dbms/fatyanosa/Server1/Suggestion Mining/Architecture/LSTM.h5\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2709 - f1_m: 0.4335 - val_loss: 0.2642 - val_f1_m: 0.3098\n",
      "Epoch 2/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2706 - f1_m: 0.4373\n",
      "Epoch 00002: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2705 - f1_m: 0.4364 - val_loss: 0.2642 - val_f1_m: 0.3098\n",
      "Epoch 3/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4364\n",
      "Epoch 00003: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4366 - val_loss: 0.2658 - val_f1_m: 0.3098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2706 - f1_m: 0.4380\n",
      "Epoch 00004: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4371 - val_loss: 0.2656 - val_f1_m: 0.3098\n",
      "Epoch 5/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4371\n",
      "Epoch 00005: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2704 - f1_m: 0.4366 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 6/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4371\n",
      "Epoch 00006: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2704 - f1_m: 0.4369 - val_loss: 0.2644 - val_f1_m: 0.3098\n",
      "Epoch 7/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4370\n",
      "Epoch 00007: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4372 - val_loss: 0.2647 - val_f1_m: 0.3098\n",
      "Epoch 8/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4367\n",
      "Epoch 00008: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4366 - val_loss: 0.2646 - val_f1_m: 0.3098\n",
      "Epoch 9/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4361\n",
      "Epoch 00009: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4363 - val_loss: 0.2646 - val_f1_m: 0.3098\n",
      "Epoch 10/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4365\n",
      "Epoch 00010: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2704 - f1_m: 0.4367 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 11/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4366\n",
      "Epoch 00011: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4365 - val_loss: 0.2647 - val_f1_m: 0.3098\n",
      "Epoch 00011: early stopping\n",
      "621.8490405082703\n",
      "0.41586998087954113\n",
      "Build model...\n",
      "Train...\n",
      "Train on 9900 samples, validate on 1657 samples\n",
      "Epoch 1/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2708 - f1_m: 0.4316\n",
      "Epoch 00001: val_f1_m improved from -inf to 0.30977, saving model to /lab/dbms/fatyanosa/Server1/Suggestion Mining/Architecture/LSTM.h5\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2708 - f1_m: 0.4319 - val_loss: 0.2641 - val_f1_m: 0.3098\n",
      "Epoch 2/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4355\n",
      "Epoch 00002: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2704 - f1_m: 0.4346 - val_loss: 0.2656 - val_f1_m: 0.3098\n",
      "Epoch 3/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4376\n",
      "Epoch 00003: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4375 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 4/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4374\n",
      "Epoch 00004: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2704 - f1_m: 0.4373 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 5/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4366\n",
      "Epoch 00005: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4365 - val_loss: 0.2644 - val_f1_m: 0.3098\n",
      "Epoch 6/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4365\n",
      "Epoch 00006: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4351 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 7/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4372\n",
      "Epoch 00007: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2704 - f1_m: 0.4367 - val_loss: 0.2646 - val_f1_m: 0.3098\n",
      "Epoch 8/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4370\n",
      "Epoch 00008: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2705 - f1_m: 0.4369 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 9/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4368\n",
      "Epoch 00009: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2704 - f1_m: 0.4370 - val_loss: 0.2642 - val_f1_m: 0.3098\n",
      "Epoch 10/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4366\n",
      "Epoch 00010: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 54s 5ms/sample - loss: 0.2704 - f1_m: 0.4368 - val_loss: 0.2651 - val_f1_m: 0.3098\n",
      "Epoch 11/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4376\n",
      "Epoch 00011: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 52s 5ms/sample - loss: 0.2705 - f1_m: 0.4371 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 00011: early stopping\n",
      "623.6387550830841\n",
      "0.41586998087954113\n",
      "Build model...\n",
      "Train...\n",
      "Train on 9900 samples, validate on 1657 samples\n",
      "Epoch 1/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2707 - f1_m: 0.4333\n",
      "Epoch 00001: val_f1_m improved from -inf to 0.30977, saving model to /lab/dbms/fatyanosa/Server1/Suggestion Mining/Architecture/LSTM.h5\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2707 - f1_m: 0.4335 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 2/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2706 - f1_m: 0.4367\n",
      "Epoch 00002: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2706 - f1_m: 0.4366 - val_loss: 0.2644 - val_f1_m: 0.3098\n",
      "Epoch 3/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4369\n",
      "Epoch 00003: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 54s 6ms/sample - loss: 0.2704 - f1_m: 0.4360 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 4/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4365\n",
      "Epoch 00004: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4367 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 5/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2703 - f1_m: 0.4364\n",
      "Epoch 00005: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2704 - f1_m: 0.4371 - val_loss: 0.2653 - val_f1_m: 0.3098\n",
      "Epoch 6/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4368\n",
      "Epoch 00006: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 54s 5ms/sample - loss: 0.2705 - f1_m: 0.4370 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 7/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4372\n",
      "Epoch 00007: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2704 - f1_m: 0.4371 - val_loss: 0.2644 - val_f1_m: 0.3098\n",
      "Epoch 8/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4367\n",
      "Epoch 00008: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 52s 5ms/sample - loss: 0.2704 - f1_m: 0.4366 - val_loss: 0.2642 - val_f1_m: 0.3098\n",
      "Epoch 9/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4363\n",
      "Epoch 00009: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 52s 5ms/sample - loss: 0.2704 - f1_m: 0.4354 - val_loss: 0.2641 - val_f1_m: 0.3098\n",
      "Epoch 10/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2703 - f1_m: 0.4362\n",
      "Epoch 00010: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 54s 5ms/sample - loss: 0.2704 - f1_m: 0.4367 - val_loss: 0.2645 - val_f1_m: 0.3098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2703 - f1_m: 0.4369\n",
      "Epoch 00011: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 54s 5ms/sample - loss: 0.2703 - f1_m: 0.4368 - val_loss: 0.2647 - val_f1_m: 0.3098\n",
      "Epoch 00011: early stopping\n",
      "600.3656523227692\n",
      "0.41586998087954113\n",
      "Build model...\n",
      "Train...\n",
      "Train on 9900 samples, validate on 1657 samples\n",
      "Epoch 1/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2708 - f1_m: 0.4244\n",
      "Epoch 00001: val_f1_m improved from -inf to 0.30977, saving model to /lab/dbms/fatyanosa/Server1/Suggestion Mining/Architecture/LSTM.h5\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2708 - f1_m: 0.4240 - val_loss: 0.2654 - val_f1_m: 0.3098\n",
      "Epoch 2/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4359\n",
      "Epoch 00002: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 53s 5ms/sample - loss: 0.2705 - f1_m: 0.4367 - val_loss: 0.2641 - val_f1_m: 0.3098\n",
      "Epoch 3/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4364\n",
      "Epoch 00003: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 53s 5ms/sample - loss: 0.2705 - f1_m: 0.4366 - val_loss: 0.2642 - val_f1_m: 0.3098\n",
      "Epoch 4/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4374\n",
      "Epoch 00004: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 52s 5ms/sample - loss: 0.2704 - f1_m: 0.4369 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 5/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4367\n",
      "Epoch 00005: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 53s 5ms/sample - loss: 0.2705 - f1_m: 0.4362 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 6/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4371\n",
      "Epoch 00006: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4369 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 7/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4365\n",
      "Epoch 00007: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4363 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 8/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4367\n",
      "Epoch 00008: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2703 - f1_m: 0.4358 - val_loss: 0.2655 - val_f1_m: 0.3098\n",
      "Epoch 9/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4366\n",
      "Epoch 00009: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2704 - f1_m: 0.4371 - val_loss: 0.2649 - val_f1_m: 0.3098\n",
      "Epoch 10/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2703 - f1_m: 0.4357\n",
      "Epoch 00010: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2704 - f1_m: 0.4367 - val_loss: 0.2657 - val_f1_m: 0.3098\n",
      "Epoch 11/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4371\n",
      "Epoch 00011: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2705 - f1_m: 0.4376 - val_loss: 0.2644 - val_f1_m: 0.3098\n",
      "Epoch 00011: early stopping\n",
      "607.7071549892426\n",
      "0.41586998087954113\n",
      "Build model...\n",
      "Train...\n",
      "Train on 9900 samples, validate on 1657 samples\n",
      "Epoch 1/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2706 - f1_m: 0.4208\n",
      "Epoch 00001: val_f1_m improved from -inf to 0.30977, saving model to /lab/dbms/fatyanosa/Server1/Suggestion Mining/Architecture/LSTM.h5\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2706 - f1_m: 0.4211 - val_loss: 0.2670 - val_f1_m: 0.3098\n",
      "Epoch 2/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2706 - f1_m: 0.4360\n",
      "Epoch 00002: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2707 - f1_m: 0.4370 - val_loss: 0.2648 - val_f1_m: 0.3098\n",
      "Epoch 3/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2706 - f1_m: 0.4360\n",
      "Epoch 00003: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4355 - val_loss: 0.2642 - val_f1_m: 0.3098\n",
      "Epoch 4/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4365\n",
      "Epoch 00004: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4364 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 5/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2706 - f1_m: 0.4370\n",
      "Epoch 00005: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4366 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 6/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4370\n",
      "Epoch 00006: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4368 - val_loss: 0.2648 - val_f1_m: 0.3098\n",
      "Epoch 7/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2703 - f1_m: 0.4363\n",
      "Epoch 00007: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4375 - val_loss: 0.2650 - val_f1_m: 0.3098\n",
      "Epoch 8/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2703 - f1_m: 0.4372\n",
      "Epoch 00008: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4377 - val_loss: 0.2660 - val_f1_m: 0.3098\n",
      "Epoch 9/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4301\n",
      "Epoch 00009: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4306 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 10/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4365\n",
      "Epoch 00010: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4367 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 11/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4361\n",
      "Epoch 00011: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4359 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 00011: early stopping\n",
      "620.5097925662994\n",
      "0.41586998087954113\n",
      "Build model...\n",
      "Train...\n",
      "Train on 9900 samples, validate on 1657 samples\n",
      "Epoch 1/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2708 - f1_m: 0.4296\n",
      "Epoch 00001: val_f1_m improved from -inf to 0.30977, saving model to /lab/dbms/fatyanosa/Server1/Suggestion Mining/Architecture/LSTM.h5\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2707 - f1_m: 0.4292 - val_loss: 0.2642 - val_f1_m: 0.3098\n",
      "Epoch 2/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2706 - f1_m: 0.4285\n",
      "Epoch 00002: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2706 - f1_m: 0.4284 - val_loss: 0.2641 - val_f1_m: 0.3098\n",
      "Epoch 3/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2706 - f1_m: 0.4364\n",
      "Epoch 00003: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2706 - f1_m: 0.4369 - val_loss: 0.2648 - val_f1_m: 0.3098\n",
      "Epoch 4/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4368\n",
      "Epoch 00004: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2705 - f1_m: 0.4367 - val_loss: 0.2649 - val_f1_m: 0.3098\n",
      "Epoch 5/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4362\n",
      "Epoch 00005: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2705 - f1_m: 0.4364 - val_loss: 0.2646 - val_f1_m: 0.3098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4358\n",
      "Epoch 00006: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4360 - val_loss: 0.2644 - val_f1_m: 0.3098\n",
      "Epoch 7/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4365\n",
      "Epoch 00007: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2705 - f1_m: 0.4364 - val_loss: 0.2646 - val_f1_m: 0.3098\n",
      "Epoch 8/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4372\n",
      "Epoch 00008: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4374 - val_loss: 0.2646 - val_f1_m: 0.3098\n",
      "Epoch 9/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4357\n",
      "Epoch 00009: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4356 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 10/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4374\n",
      "Epoch 00010: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4376 - val_loss: 0.2646 - val_f1_m: 0.3098\n",
      "Epoch 11/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4361\n",
      "Epoch 00011: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2704 - f1_m: 0.4360 - val_loss: 0.2644 - val_f1_m: 0.3098\n",
      "Epoch 00011: early stopping\n",
      "624.1448194980621\n",
      "0.41586998087954113\n",
      "Build model...\n",
      "Train...\n",
      "Train on 9900 samples, validate on 1657 samples\n",
      "Epoch 1/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2708 - f1_m: 0.4323\n",
      "Epoch 00001: val_f1_m improved from -inf to 0.30977, saving model to /lab/dbms/fatyanosa/Server1/Suggestion Mining/Architecture/LSTM.h5\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2707 - f1_m: 0.4322 - val_loss: 0.2641 - val_f1_m: 0.3098\n",
      "Epoch 2/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2707 - f1_m: 0.4365\n",
      "Epoch 00002: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2706 - f1_m: 0.4356 - val_loss: 0.2656 - val_f1_m: 0.3098\n",
      "Epoch 3/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4328\n",
      "Epoch 00003: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4327 - val_loss: 0.2642 - val_f1_m: 0.3098\n",
      "Epoch 4/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4377\n",
      "Epoch 00004: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2706 - f1_m: 0.4379 - val_loss: 0.2652 - val_f1_m: 0.3098\n",
      "Epoch 5/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4367\n",
      "Epoch 00005: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2705 - f1_m: 0.4366 - val_loss: 0.2644 - val_f1_m: 0.3098\n",
      "Epoch 6/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4365\n",
      "Epoch 00006: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4370 - val_loss: 0.2644 - val_f1_m: 0.3098\n",
      "Epoch 7/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4372\n",
      "Epoch 00007: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 54s 5ms/sample - loss: 0.2704 - f1_m: 0.4370 - val_loss: 0.2644 - val_f1_m: 0.3098\n",
      "Epoch 8/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4366\n",
      "Epoch 00008: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4365 - val_loss: 0.2649 - val_f1_m: 0.3098\n",
      "Epoch 9/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4362\n",
      "Epoch 00009: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4364 - val_loss: 0.2647 - val_f1_m: 0.3098\n",
      "Epoch 10/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4366\n",
      "Epoch 00010: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4370 - val_loss: 0.2646 - val_f1_m: 0.3098\n",
      "Epoch 11/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4367\n",
      "Epoch 00011: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4366 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 00011: early stopping\n",
      "618.020702123642\n",
      "0.41586998087954113\n",
      "Build model...\n",
      "Train...\n",
      "Train on 9900 samples, validate on 1657 samples\n",
      "Epoch 1/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2707 - f1_m: 0.4113\n",
      "Epoch 00001: val_f1_m improved from -inf to 0.30977, saving model to /lab/dbms/fatyanosa/Server1/Suggestion Mining/Architecture/LSTM.h5\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2707 - f1_m: 0.4119 - val_loss: 0.2644 - val_f1_m: 0.3098\n",
      "Epoch 2/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2707 - f1_m: 0.4366\n",
      "Epoch 00002: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2707 - f1_m: 0.4362 - val_loss: 0.2642 - val_f1_m: 0.3098\n",
      "Epoch 3/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4364\n",
      "Epoch 00003: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4362 - val_loss: 0.2654 - val_f1_m: 0.3098\n",
      "Epoch 4/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4365\n",
      "Epoch 00004: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2705 - f1_m: 0.4367 - val_loss: 0.2656 - val_f1_m: 0.3098\n",
      "Epoch 5/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4303\n",
      "Epoch 00005: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4311 - val_loss: 0.2642 - val_f1_m: 0.3098\n",
      "Epoch 6/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4359\n",
      "Epoch 00006: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2704 - f1_m: 0.4358 - val_loss: 0.2656 - val_f1_m: 0.3098\n",
      "Epoch 7/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4369\n",
      "Epoch 00007: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 53s 5ms/sample - loss: 0.2705 - f1_m: 0.4371 - val_loss: 0.2646 - val_f1_m: 0.3098\n",
      "Epoch 8/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4371\n",
      "Epoch 00008: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 54s 5ms/sample - loss: 0.2705 - f1_m: 0.4376 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 9/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4371\n",
      "Epoch 00009: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4369 - val_loss: 0.2649 - val_f1_m: 0.3098\n",
      "Epoch 10/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4370\n",
      "Epoch 00010: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2704 - f1_m: 0.4372 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 11/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4375\n",
      "Epoch 00011: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2704 - f1_m: 0.4382 - val_loss: 0.2648 - val_f1_m: 0.3098\n",
      "Epoch 00011: early stopping\n",
      "611.0554542541504\n",
      "0.41586998087954113\n",
      "Build model...\n",
      "Train...\n",
      "Train on 9900 samples, validate on 1657 samples\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2708 - f1_m: 0.4246\n",
      "Epoch 00001: val_f1_m improved from -inf to 0.30977, saving model to /lab/dbms/fatyanosa/Server1/Suggestion Mining/Architecture/LSTM.h5\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2709 - f1_m: 0.4248 - val_loss: 0.2649 - val_f1_m: 0.3098\n",
      "Epoch 2/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2706 - f1_m: 0.4363\n",
      "Epoch 00002: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 54s 5ms/sample - loss: 0.2706 - f1_m: 0.4362 - val_loss: 0.2642 - val_f1_m: 0.3098\n",
      "Epoch 3/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2706 - f1_m: 0.4367\n",
      "Epoch 00003: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2706 - f1_m: 0.4369 - val_loss: 0.2642 - val_f1_m: 0.3098\n",
      "Epoch 4/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2703 - f1_m: 0.4360\n",
      "Epoch 00004: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2703 - f1_m: 0.4362 - val_loss: 0.2642 - val_f1_m: 0.3098\n",
      "Epoch 5/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2706 - f1_m: 0.4373\n",
      "Epoch 00005: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2705 - f1_m: 0.4364 - val_loss: 0.2649 - val_f1_m: 0.3098\n",
      "Epoch 6/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4357\n",
      "Epoch 00006: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2705 - f1_m: 0.4362 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 7/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4363\n",
      "Epoch 00007: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4370 - val_loss: 0.2652 - val_f1_m: 0.3098\n",
      "Epoch 8/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4364\n",
      "Epoch 00008: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4359 - val_loss: 0.2646 - val_f1_m: 0.3098\n",
      "Epoch 9/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4362\n",
      "Epoch 00009: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2704 - f1_m: 0.4357 - val_loss: 0.2647 - val_f1_m: 0.3098\n",
      "Epoch 10/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2703 - f1_m: 0.4372\n",
      "Epoch 00010: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2703 - f1_m: 0.4374 - val_loss: 0.2641 - val_f1_m: 0.3098\n",
      "Epoch 11/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4367\n",
      "Epoch 00011: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2704 - f1_m: 0.4362 - val_loss: 0.2646 - val_f1_m: 0.3098\n",
      "Epoch 00011: early stopping\n",
      "620.5717704296112\n",
      "0.41586998087954113\n",
      "Build model...\n",
      "Train...\n",
      "Train on 9900 samples, validate on 1657 samples\n",
      "Epoch 1/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2707 - f1_m: 0.3984\n",
      "Epoch 00001: val_f1_m improved from -inf to 0.30977, saving model to /lab/dbms/fatyanosa/Server1/Suggestion Mining/Architecture/LSTM.h5\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2707 - f1_m: 0.3984 - val_loss: 0.2642 - val_f1_m: 0.3098\n",
      "Epoch 2/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4367\n",
      "Epoch 00002: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4375 - val_loss: 0.2641 - val_f1_m: 0.3098\n",
      "Epoch 3/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4366\n",
      "Epoch 00003: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2704 - f1_m: 0.4361 - val_loss: 0.2652 - val_f1_m: 0.3098\n",
      "Epoch 4/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4261\n",
      "Epoch 00004: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2704 - f1_m: 0.4256 - val_loss: 0.2682 - val_f1_m: 0.3098\n",
      "Epoch 5/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4371\n",
      "Epoch 00005: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2705 - f1_m: 0.4370 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 6/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4368\n",
      "Epoch 00006: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2704 - f1_m: 0.4367 - val_loss: 0.2647 - val_f1_m: 0.3098\n",
      "Epoch 7/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4368\n",
      "Epoch 00007: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2705 - f1_m: 0.4373 - val_loss: 0.2644 - val_f1_m: 0.3098\n",
      "Epoch 8/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4359\n",
      "Epoch 00008: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4361 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 9/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2702 - f1_m: 0.4364\n",
      "Epoch 00009: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2703 - f1_m: 0.4369 - val_loss: 0.2677 - val_f1_m: 0.3098\n",
      "Epoch 10/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4356\n",
      "Epoch 00010: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4361 - val_loss: 0.2646 - val_f1_m: 0.3098\n",
      "Epoch 11/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4354\n",
      "Epoch 00011: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2704 - f1_m: 0.4353 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 00011: early stopping\n",
      "628.1214518547058\n",
      "0.41586998087954113\n",
      "Build model...\n",
      "Train...\n",
      "Train on 9900 samples, validate on 1657 samples\n",
      "Epoch 1/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2706 - f1_m: 0.4093\n",
      "Epoch 00001: val_f1_m improved from -inf to 0.30977, saving model to /lab/dbms/fatyanosa/Server1/Suggestion Mining/Architecture/LSTM.h5\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2706 - f1_m: 0.4093 - val_loss: 0.2646 - val_f1_m: 0.3098\n",
      "Epoch 2/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2706 - f1_m: 0.4355\n",
      "Epoch 00002: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2706 - f1_m: 0.4357 - val_loss: 0.2648 - val_f1_m: 0.3098\n",
      "Epoch 3/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4371\n",
      "Epoch 00003: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4366 - val_loss: 0.2644 - val_f1_m: 0.3098\n",
      "Epoch 4/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4369\n",
      "Epoch 00004: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 54s 5ms/sample - loss: 0.2705 - f1_m: 0.4371 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 5/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4363\n",
      "Epoch 00005: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4365 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 6/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4375\n",
      "Epoch 00006: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4370 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 7/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4360\n",
      "Epoch 00007: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4355 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 8/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4362\n",
      "Epoch 00008: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4364 - val_loss: 0.2642 - val_f1_m: 0.3098\n",
      "Epoch 9/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4366\n",
      "Epoch 00009: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2705 - f1_m: 0.4365 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 10/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2703 - f1_m: 0.4365\n",
      "Epoch 00010: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2703 - f1_m: 0.4367 - val_loss: 0.2644 - val_f1_m: 0.3098\n",
      "Epoch 11/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2703 - f1_m: 0.4360\n",
      "Epoch 00011: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2704 - f1_m: 0.4367 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 00011: early stopping\n",
      "619.1944615840912\n",
      "0.41586998087954113\n",
      "Build model...\n",
      "Train...\n",
      "Train on 9900 samples, validate on 1657 samples\n",
      "Epoch 1/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2711 - f1_m: 0.4275\n",
      "Epoch 00001: val_f1_m improved from -inf to 0.30977, saving model to /lab/dbms/fatyanosa/Server1/Suggestion Mining/Architecture/LSTM.h5\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2711 - f1_m: 0.4271 - val_loss: 0.2650 - val_f1_m: 0.3098\n",
      "Epoch 2/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4371\n",
      "Epoch 00002: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2704 - f1_m: 0.4373 - val_loss: 0.2642 - val_f1_m: 0.3098\n",
      "Epoch 3/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4352\n",
      "Epoch 00003: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2705 - f1_m: 0.4354 - val_loss: 0.2647 - val_f1_m: 0.3098\n",
      "Epoch 4/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4372\n",
      "Epoch 00004: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2705 - f1_m: 0.4374 - val_loss: 0.2654 - val_f1_m: 0.3098\n",
      "Epoch 5/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4365\n",
      "Epoch 00005: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2705 - f1_m: 0.4363 - val_loss: 0.2648 - val_f1_m: 0.3098\n",
      "Epoch 6/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4356\n",
      "Epoch 00006: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2705 - f1_m: 0.4361 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 7/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4364\n",
      "Epoch 00007: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2705 - f1_m: 0.4359 - val_loss: 0.2647 - val_f1_m: 0.3098\n",
      "Epoch 8/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4366\n",
      "Epoch 00008: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 54s 5ms/sample - loss: 0.2704 - f1_m: 0.4368 - val_loss: 0.2649 - val_f1_m: 0.3098\n",
      "Epoch 9/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2703 - f1_m: 0.4364\n",
      "Epoch 00009: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4369 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 10/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2703 - f1_m: 0.4342\n",
      "Epoch 00010: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 54s 5ms/sample - loss: 0.2703 - f1_m: 0.4333 - val_loss: 0.2644 - val_f1_m: 0.3098\n",
      "Epoch 11/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2703 - f1_m: 0.4352\n",
      "Epoch 00011: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 54s 5ms/sample - loss: 0.2704 - f1_m: 0.4360 - val_loss: 0.2648 - val_f1_m: 0.3098\n",
      "Epoch 00011: early stopping\n",
      "609.9198160171509\n",
      "0.41586998087954113\n",
      "Build model...\n",
      "Train...\n",
      "Train on 9900 samples, validate on 1657 samples\n",
      "Epoch 1/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2708 - f1_m: 0.4305\n",
      "Epoch 00001: val_f1_m improved from -inf to 0.30977, saving model to /lab/dbms/fatyanosa/Server1/Suggestion Mining/Architecture/LSTM.h5\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2707 - f1_m: 0.4300 - val_loss: 0.2641 - val_f1_m: 0.3098\n",
      "Epoch 2/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2706 - f1_m: 0.4377\n",
      "Epoch 00002: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2706 - f1_m: 0.4375 - val_loss: 0.2647 - val_f1_m: 0.3098\n",
      "Epoch 3/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2707 - f1_m: 0.4371\n",
      "Epoch 00003: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2706 - f1_m: 0.4362 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 4/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4366\n",
      "Epoch 00004: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4364 - val_loss: 0.2642 - val_f1_m: 0.3098\n",
      "Epoch 5/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4369\n",
      "Epoch 00005: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2704 - f1_m: 0.4360 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 6/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4367\n",
      "Epoch 00006: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 54s 5ms/sample - loss: 0.2705 - f1_m: 0.4362 - val_loss: 0.2650 - val_f1_m: 0.3098\n",
      "Epoch 7/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4369\n",
      "Epoch 00007: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2704 - f1_m: 0.4355 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 8/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4367\n",
      "Epoch 00008: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2705 - f1_m: 0.4366 - val_loss: 0.2652 - val_f1_m: 0.3098\n",
      "Epoch 9/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4370\n",
      "Epoch 00009: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4372 - val_loss: 0.2647 - val_f1_m: 0.3098\n",
      "Epoch 10/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2703 - f1_m: 0.4370\n",
      "Epoch 00010: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2704 - f1_m: 0.4375 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 11/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4373\n",
      "Epoch 00011: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2704 - f1_m: 0.4372 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 00011: early stopping\n",
      "614.5344750881195\n",
      "0.41586998087954113\n",
      "Build model...\n",
      "Train...\n",
      "Train on 9900 samples, validate on 1657 samples\n",
      "Epoch 1/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2709 - f1_m: 0.4248\n",
      "Epoch 00001: val_f1_m improved from -inf to 0.30977, saving model to /lab/dbms/fatyanosa/Server1/Suggestion Mining/Architecture/LSTM.h5\n",
      "9900/9900 [==============================] - 60s 6ms/sample - loss: 0.2708 - f1_m: 0.4239 - val_loss: 0.2643 - val_f1_m: 0.3098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4369\n",
      "Epoch 00002: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4368 - val_loss: 0.2642 - val_f1_m: 0.3098\n",
      "Epoch 3/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2706 - f1_m: 0.4362\n",
      "Epoch 00003: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 55s 6ms/sample - loss: 0.2706 - f1_m: 0.4358 - val_loss: 0.2648 - val_f1_m: 0.3098\n",
      "Epoch 4/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2706 - f1_m: 0.4363\n",
      "Epoch 00004: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2706 - f1_m: 0.4362 - val_loss: 0.2646 - val_f1_m: 0.3098\n",
      "Epoch 5/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4371\n",
      "Epoch 00005: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4366 - val_loss: 0.2658 - val_f1_m: 0.3098\n",
      "Epoch 6/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4362\n",
      "Epoch 00006: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 53s 5ms/sample - loss: 0.2705 - f1_m: 0.4364 - val_loss: 0.2644 - val_f1_m: 0.3098\n",
      "Epoch 7/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4372\n",
      "Epoch 00007: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 54s 5ms/sample - loss: 0.2705 - f1_m: 0.4363 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 8/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4365\n",
      "Epoch 00008: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 53s 5ms/sample - loss: 0.2705 - f1_m: 0.4364 - val_loss: 0.2647 - val_f1_m: 0.3098\n",
      "Epoch 9/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4371\n",
      "Epoch 00009: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4370 - val_loss: 0.2646 - val_f1_m: 0.3098\n",
      "Epoch 10/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4365\n",
      "Epoch 00010: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2704 - f1_m: 0.4370 - val_loss: 0.2647 - val_f1_m: 0.3098\n",
      "Epoch 11/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4369\n",
      "Epoch 00011: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2704 - f1_m: 0.4371 - val_loss: 0.2650 - val_f1_m: 0.3098\n",
      "Epoch 00011: early stopping\n",
      "617.6947708129883\n",
      "0.41586998087954113\n",
      "Build model...\n",
      "Train...\n",
      "Train on 9900 samples, validate on 1657 samples\n",
      "Epoch 1/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2706 - f1_m: 0.4208\n",
      "Epoch 00001: val_f1_m improved from -inf to 0.30977, saving model to /lab/dbms/fatyanosa/Server1/Suggestion Mining/Architecture/LSTM.h5\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2706 - f1_m: 0.4207 - val_loss: 0.2654 - val_f1_m: 0.3098\n",
      "Epoch 2/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4372\n",
      "Epoch 00002: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2704 - f1_m: 0.4371 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 3/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2706 - f1_m: 0.4365\n",
      "Epoch 00003: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2706 - f1_m: 0.4360 - val_loss: 0.2647 - val_f1_m: 0.3098\n",
      "Epoch 4/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4372\n",
      "Epoch 00004: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2704 - f1_m: 0.4374 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 5/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2706 - f1_m: 0.4354\n",
      "Epoch 00005: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2705 - f1_m: 0.4345 - val_loss: 0.2654 - val_f1_m: 0.3098\n",
      "Epoch 6/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4365\n",
      "Epoch 00006: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2705 - f1_m: 0.4369 - val_loss: 0.2641 - val_f1_m: 0.3098\n",
      "Epoch 7/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4357\n",
      "Epoch 00007: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2705 - f1_m: 0.4359 - val_loss: 0.2646 - val_f1_m: 0.3098\n",
      "Epoch 8/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4371\n",
      "Epoch 00008: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2704 - f1_m: 0.4370 - val_loss: 0.2647 - val_f1_m: 0.3098\n",
      "Epoch 9/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4381\n",
      "Epoch 00009: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4379 - val_loss: 0.2647 - val_f1_m: 0.3098\n",
      "Epoch 10/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4359\n",
      "Epoch 00010: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2704 - f1_m: 0.4354 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 11/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4367\n",
      "Epoch 00011: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4366 - val_loss: 0.2647 - val_f1_m: 0.3098\n",
      "Epoch 00011: early stopping\n",
      "635.1633825302124\n",
      "0.41586998087954113\n",
      "Build model...\n",
      "Train...\n",
      "Train on 9900 samples, validate on 1657 samples\n",
      "Epoch 1/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2708 - f1_m: 0.4368\n",
      "Epoch 00001: val_f1_m improved from -inf to 0.30977, saving model to /lab/dbms/fatyanosa/Server1/Suggestion Mining/Architecture/LSTM.h5\n",
      "9900/9900 [==============================] - 61s 6ms/sample - loss: 0.2708 - f1_m: 0.4370 - val_loss: 0.2641 - val_f1_m: 0.3098\n",
      "Epoch 2/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2707 - f1_m: 0.4340\n",
      "Epoch 00002: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2707 - f1_m: 0.4335 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 3/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4368\n",
      "Epoch 00003: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2705 - f1_m: 0.4370 - val_loss: 0.2651 - val_f1_m: 0.3098\n",
      "Epoch 4/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2703 - f1_m: 0.4365\n",
      "Epoch 00004: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2704 - f1_m: 0.4374 - val_loss: 0.2655 - val_f1_m: 0.3098\n",
      "Epoch 5/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4361\n",
      "Epoch 00005: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2705 - f1_m: 0.4369 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 6/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4364\n",
      "Epoch 00006: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2705 - f1_m: 0.4363 - val_loss: 0.2647 - val_f1_m: 0.3098\n",
      "Epoch 7/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4368\n",
      "Epoch 00007: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2704 - f1_m: 0.4366 - val_loss: 0.2646 - val_f1_m: 0.3098\n",
      "Epoch 8/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4359\n",
      "Epoch 00008: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2704 - f1_m: 0.4361 - val_loss: 0.2645 - val_f1_m: 0.3098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4375\n",
      "Epoch 00009: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2704 - f1_m: 0.4374 - val_loss: 0.2644 - val_f1_m: 0.3098\n",
      "Epoch 10/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2703 - f1_m: 0.4363\n",
      "Epoch 00010: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2704 - f1_m: 0.4373 - val_loss: 0.2662 - val_f1_m: 0.3098\n",
      "Epoch 11/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4365\n",
      "Epoch 00011: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2704 - f1_m: 0.4367 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 00011: early stopping\n",
      "649.5211544036865\n",
      "0.41586998087954113\n",
      "Build model...\n",
      "Train...\n",
      "Train on 9900 samples, validate on 1657 samples\n",
      "Epoch 1/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2707 - f1_m: 0.4191\n",
      "Epoch 00001: val_f1_m improved from -inf to 0.30977, saving model to /lab/dbms/fatyanosa/Server1/Suggestion Mining/Architecture/LSTM.h5\n",
      "9900/9900 [==============================] - 61s 6ms/sample - loss: 0.2707 - f1_m: 0.4193 - val_loss: 0.2655 - val_f1_m: 0.3098\n",
      "Epoch 2/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2706 - f1_m: 0.4370\n",
      "Epoch 00002: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2706 - f1_m: 0.4368 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 3/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4362\n",
      "Epoch 00003: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2705 - f1_m: 0.4361 - val_loss: 0.2642 - val_f1_m: 0.3098\n",
      "Epoch 4/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2703 - f1_m: 0.4363\n",
      "Epoch 00004: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2704 - f1_m: 0.4370 - val_loss: 0.2641 - val_f1_m: 0.3098\n",
      "Epoch 5/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4368\n",
      "Epoch 00005: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2705 - f1_m: 0.4363 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 6/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4374\n",
      "Epoch 00006: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2703 - f1_m: 0.4369 - val_loss: 0.2642 - val_f1_m: 0.3098\n",
      "Epoch 7/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4364\n",
      "Epoch 00007: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2705 - f1_m: 0.4363 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 8/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4365\n",
      "Epoch 00008: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2704 - f1_m: 0.4360 - val_loss: 0.2651 - val_f1_m: 0.3098\n",
      "Epoch 9/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4372\n",
      "Epoch 00009: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2704 - f1_m: 0.4363 - val_loss: 0.2647 - val_f1_m: 0.3098\n",
      "Epoch 10/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4364\n",
      "Epoch 00010: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2705 - f1_m: 0.4366 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 11/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4385\n",
      "Epoch 00011: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2703 - f1_m: 0.4376 - val_loss: 0.2641 - val_f1_m: 0.3098\n",
      "Epoch 00011: early stopping\n",
      "644.9818530082703\n",
      "0.41586998087954113\n",
      "Build model...\n",
      "Train...\n",
      "Train on 9900 samples, validate on 1657 samples\n",
      "Epoch 1/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2707 - f1_m: 0.4334\n",
      "Epoch 00001: val_f1_m improved from -inf to 0.30977, saving model to /lab/dbms/fatyanosa/Server1/Suggestion Mining/Architecture/LSTM.h5\n",
      "9900/9900 [==============================] - 60s 6ms/sample - loss: 0.2707 - f1_m: 0.4325 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 2/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2706 - f1_m: 0.4370\n",
      "Epoch 00002: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2706 - f1_m: 0.4365 - val_loss: 0.2641 - val_f1_m: 0.3098\n",
      "Epoch 3/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4367\n",
      "Epoch 00003: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2705 - f1_m: 0.4366 - val_loss: 0.2652 - val_f1_m: 0.3098\n",
      "Epoch 4/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4361\n",
      "Epoch 00004: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2704 - f1_m: 0.4363 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 5/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4361\n",
      "Epoch 00005: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2705 - f1_m: 0.4360 - val_loss: 0.2644 - val_f1_m: 0.3098\n",
      "Epoch 6/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4372\n",
      "Epoch 00006: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2704 - f1_m: 0.4371 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 7/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4364\n",
      "Epoch 00007: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2704 - f1_m: 0.4354 - val_loss: 0.2646 - val_f1_m: 0.3098\n",
      "Epoch 8/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4363\n",
      "Epoch 00008: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 60s 6ms/sample - loss: 0.2704 - f1_m: 0.4358 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 9/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4366\n",
      "Epoch 00009: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2705 - f1_m: 0.4364 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 10/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4371\n",
      "Epoch 00010: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2705 - f1_m: 0.4366 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 11/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4366\n",
      "Epoch 00011: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2704 - f1_m: 0.4368 - val_loss: 0.2644 - val_f1_m: 0.3098\n",
      "Epoch 00011: early stopping\n",
      "651.0141370296478\n",
      "0.41586998087954113\n",
      "Build model...\n",
      "Train...\n",
      "Train on 9900 samples, validate on 1657 samples\n",
      "Epoch 1/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2708 - f1_m: 0.4318\n",
      "Epoch 00001: val_f1_m improved from -inf to 0.30977, saving model to /lab/dbms/fatyanosa/Server1/Suggestion Mining/Architecture/LSTM.h5\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2708 - f1_m: 0.4320 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 2/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4364\n",
      "Epoch 00002: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2705 - f1_m: 0.4359 - val_loss: 0.2642 - val_f1_m: 0.3098\n",
      "Epoch 3/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4376\n",
      "Epoch 00003: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2705 - f1_m: 0.4374 - val_loss: 0.2653 - val_f1_m: 0.3098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4369\n",
      "Epoch 00004: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4368 - val_loss: 0.2646 - val_f1_m: 0.3098\n",
      "Epoch 5/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4335\n",
      "Epoch 00005: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2704 - f1_m: 0.4334 - val_loss: 0.2644 - val_f1_m: 0.3098\n",
      "Epoch 6/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4379\n",
      "Epoch 00006: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2704 - f1_m: 0.4381 - val_loss: 0.2646 - val_f1_m: 0.3098\n",
      "Epoch 7/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4372\n",
      "Epoch 00007: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2704 - f1_m: 0.4370 - val_loss: 0.2644 - val_f1_m: 0.3098\n",
      "Epoch 8/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4371\n",
      "Epoch 00008: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2705 - f1_m: 0.4362 - val_loss: 0.2651 - val_f1_m: 0.3098\n",
      "Epoch 9/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4338\n",
      "Epoch 00009: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2704 - f1_m: 0.4324 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 10/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4365\n",
      "Epoch 00010: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 56s 6ms/sample - loss: 0.2705 - f1_m: 0.4374 - val_loss: 0.2645 - val_f1_m: 0.3098\n",
      "Epoch 11/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4367\n",
      "Epoch 00011: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2704 - f1_m: 0.4366 - val_loss: 0.2642 - val_f1_m: 0.3098\n",
      "Epoch 00011: early stopping\n",
      "639.33349776268\n",
      "0.41586998087954113\n",
      "Build model...\n",
      "Train...\n",
      "Train on 9900 samples, validate on 1657 samples\n",
      "Epoch 1/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2707 - f1_m: 0.4344\n",
      "Epoch 00001: val_f1_m improved from -inf to 0.30977, saving model to /lab/dbms/fatyanosa/Server1/Suggestion Mining/Architecture/LSTM.h5\n",
      "9900/9900 [==============================] - 60s 6ms/sample - loss: 0.2707 - f1_m: 0.4335 - val_loss: 0.2641 - val_f1_m: 0.3098\n",
      "Epoch 2/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2706 - f1_m: 0.4355\n",
      "Epoch 00002: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2706 - f1_m: 0.4358 - val_loss: 0.2642 - val_f1_m: 0.3098\n",
      "Epoch 3/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2703 - f1_m: 0.4371\n",
      "Epoch 00003: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 60s 6ms/sample - loss: 0.2704 - f1_m: 0.4380 - val_loss: 0.2641 - val_f1_m: 0.3098\n",
      "Epoch 4/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4376\n",
      "Epoch 00004: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 57s 6ms/sample - loss: 0.2705 - f1_m: 0.4371 - val_loss: 0.2643 - val_f1_m: 0.3098\n",
      "Epoch 5/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4335\n",
      "Epoch 00005: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2704 - f1_m: 0.4330 - val_loss: 0.2647 - val_f1_m: 0.3098\n",
      "Epoch 6/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4366\n",
      "Epoch 00006: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2704 - f1_m: 0.4361 - val_loss: 0.2649 - val_f1_m: 0.3098\n",
      "Epoch 7/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4359\n",
      "Epoch 00007: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2704 - f1_m: 0.4364 - val_loss: 0.2641 - val_f1_m: 0.3098\n",
      "Epoch 8/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2705 - f1_m: 0.4369\n",
      "Epoch 00008: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 59s 6ms/sample - loss: 0.2704 - f1_m: 0.4364 - val_loss: 0.2647 - val_f1_m: 0.3098\n",
      "Epoch 9/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4365\n",
      "Epoch 00009: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2704 - f1_m: 0.4367 - val_loss: 0.2646 - val_f1_m: 0.3098\n",
      "Epoch 10/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2704 - f1_m: 0.4372\n",
      "Epoch 00010: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2704 - f1_m: 0.4374 - val_loss: 0.2642 - val_f1_m: 0.3098\n",
      "Epoch 11/15\n",
      "9888/9900 [============================>.] - ETA: 0s - loss: 0.2703 - f1_m: 0.4354\n",
      "Epoch 00011: val_f1_m did not improve from 0.30977\n",
      "9900/9900 [==============================] - 58s 6ms/sample - loss: 0.2703 - f1_m: 0.4356 - val_loss: 0.2650 - val_f1_m: 0.3098\n",
      "Epoch 00011: early stopping\n",
      "645.6306040287018\n",
      "0.41586998087954113\n"
     ]
    }
   ],
   "source": [
    "max_features = 20000\n",
    "# cut texts after this number of words (among top max_features most common words)\n",
    "maxlen = 80\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "# Read data\n",
    "dfTraining = util.read_CSV(datasetPath + dataTraining)\n",
    "dfTesting = util.read_CSV(datasetPath + dataTesting)\n",
    "\n",
    "# get texts and labels\n",
    "textsTraining, y_train = util.get_text_label(dfTraining)\n",
    "textsTesting, y_test = util.get_text_label(dfTesting)\n",
    "\n",
    "# Tokenize words\n",
    "tokenizer = util.tokenize_texts(textsTraining)\n",
    "x_train = tokenizer.texts_to_sequences(textsTraining)\n",
    "x_test = tokenizer.texts_to_sequences(textsTesting)\n",
    "\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "# Adding 1 because of reserved 0 index\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# get maxlen\n",
    "maxlen = util.get_max_length_of_sentences(textsTraining)\n",
    "\n",
    "# Pad sequences with zeros\n",
    "x_train = util.padding_texts(x_train, maxlen)\n",
    "x_test = util.padding_texts(x_test, maxlen)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "testing_name = \"LSTM\"\n",
    "\n",
    "# Create Testing Results\n",
    "f = open(resultsPath + testing_name + \".csv\", \"w+\")\n",
    "f.write(\"i,accuracy,precision,recall,f1Score,time\\n\")\n",
    "f.close()\n",
    "\n",
    "for i in range(0, n_run):\n",
    "    then = time.time()\n",
    "    \n",
    "    print('Build model...')\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 128))\n",
    "    model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # try using different optimizers and different optimizer configs\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=[util.f1_m])\n",
    "\n",
    "    print('Train...')\n",
    "    # save history to a file\n",
    "    callbacks = [tf.keras.callbacks.CSVLogger(str(archPath + testing_name + \".csv\"))]\n",
    "\n",
    "    #early stopping\n",
    "    callbacks += [tf.keras.callbacks.EarlyStopping(monitor='val_f1_m', mode='max', verbose=1, patience=10)]\n",
    "\n",
    "    #save the best model\n",
    "    callbacks += [tf.keras.callbacks.ModelCheckpoint(archPath + testing_name + \".h5\", monitor='val_f1_m', mode='max', verbose=1, save_best_only=True)]\n",
    "\n",
    "    class_weight = {0: 0.25,\n",
    "                    1: 0.75}\n",
    "    y_train = np.uint8(y_train)\n",
    "    y_test = np.uint8(y_test)\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=15,\n",
    "              validation_data=(x_test, y_test), \n",
    "              callbacks=callbacks, \n",
    "              class_weight=class_weight)\n",
    "#     score, acc = model.evaluate(x_test, y_test,\n",
    "#                                 batch_size=batch_size)\n",
    "#     print('Test score:', score)\n",
    "#     print('Test accuracy:', acc)\n",
    "    \n",
    "    dependencies = {\n",
    "    'f1_m': util.f1_m\n",
    "    }\n",
    "\n",
    "    # load the saved model\n",
    "    saved_model = tf.keras.models.load_model(archPath + testing_name + \".h5\", custom_objects=dependencies)\n",
    "    y_pred = saved_model.predict_classes(x_test)    \n",
    "\n",
    "    # CNN metrics\n",
    "    accuracyScore, precisionScoreBinary, recallScoreBinary, f1ScoreBinary = util.get_testing_metric(y_test, y_pred)\n",
    "\n",
    "    now = time.time()\n",
    "    diff = now - then\n",
    "    print(diff)\n",
    "    print(f1ScoreBinary)\n",
    "\n",
    "    # save testing data\n",
    "    f = open(resultsPath + testing_name + \".csv\", 'a')\n",
    "    f.write(str(i + 1)\n",
    "            + ',' + str(accuracyScore)\n",
    "            + ',' + str(precisionScoreBinary)\n",
    "            + ',' + str(recallScoreBinary)\n",
    "            + ',' + str(f1ScoreBinary)\n",
    "            + ',' + str(diff) + '\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
    "from keras.datasets import imdb\n",
    "\n",
    "\n",
    "max_features = 20000\n",
    "# cut texts after this number of words\n",
    "# (among top max_features most common words)\n",
    "maxlen = 100\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "# Read data\n",
    "dfTraining = util.read_CSV(datasetPath + dataTraining)\n",
    "dfTesting = util.read_CSV(datasetPath + dataTesting)\n",
    "\n",
    "# get texts and labels\n",
    "textsTraining, y_train = util.get_text_label(dfTraining)\n",
    "textsTesting, y_test = util.get_text_label(dfTesting)\n",
    "\n",
    "# Tokenize words\n",
    "tokenizer = util.tokenize_texts(textsTraining)\n",
    "x_train = tokenizer.texts_to_sequences(textsTraining)\n",
    "x_test = tokenizer.texts_to_sequences(textsTesting)\n",
    "\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "# Adding 1 because of reserved 0 index\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# get maxlen\n",
    "maxlen = util.get_max_length_of_sentences(textsTraining)\n",
    "\n",
    "# Pad sequences with zeros\n",
    "x_train = util.padding_texts(x_train, maxlen)\n",
    "x_test = util.padding_texts(x_test, maxlen)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "testing_name = \"BidirectionalLSTM\"\n",
    "\n",
    "# Create Testing Results\n",
    "f = open(resultsPath + testing_name + \".csv\", \"w+\")\n",
    "f.write(\"i,accuracy,precision,recall,f1Score,time\\n\")\n",
    "f.close()\n",
    "\n",
    "for i in range(0, n_run):\n",
    "    then = time.time()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 128, input_length=maxlen))\n",
    "    model.add(Bidirectional(LSTM(64)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # try using different optimizers and different optimizer configs\n",
    "    model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    print('Train...')\n",
    "    # save history to a file\n",
    "    callbacks = [tf.keras.callbacks.CSVLogger(str(archPath + testing_name + \".csv\"))]\n",
    "\n",
    "    #early stopping\n",
    "    callbacks += [tf.keras.callbacks.EarlyStopping(monitor='val_f1_m', mode='max', verbose=1, patience=10)]\n",
    "\n",
    "    #save the best model\n",
    "    callbacks += [tf.keras.callbacks.ModelCheckpoint(archPath + testing_name + \".h5\", monitor='val_f1_m', mode='max', verbose=1, save_best_only=True)]\n",
    "\n",
    "    class_weight = {0: 0.25,\n",
    "                    1: 0.75}\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=4,\n",
    "              validation_data=[x_test, y_test], \n",
    "              callbacks=callbacks, \n",
    "              class_weight=class_weight)\n",
    "    \n",
    "    dependencies = {\n",
    "    'f1_m': util.f1_m\n",
    "    }\n",
    "\n",
    "    # load the saved model\n",
    "    saved_model = tf.keras.models.load_model(archPath + testing_name + \".h5\", custom_objects=dependencies)\n",
    "    y_pred = saved_model.predict_classes(x_test)    \n",
    "\n",
    "    # CNN metrics\n",
    "    accuracyScore, precisionScoreBinary, recallScoreBinary, f1ScoreBinary = util.get_testing_metric(y_test, y_pred)\n",
    "\n",
    "    now = time.time()\n",
    "    diff = now - then\n",
    "    print(diff)\n",
    "    print(f1ScoreBinary)\n",
    "\n",
    "    # save testing data\n",
    "    f = open(resultsPath + testing_name + \".csv\", 'a')\n",
    "    f.write(str(i + 1)\n",
    "            + ',' + str(accuracyScore)\n",
    "            + ',' + str(precisionScoreBinary)\n",
    "            + ',' + str(recallScoreBinary)\n",
    "            + ',' + str(f1ScoreBinary)\n",
    "            + ',' + str(diff) + '\\n')\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
